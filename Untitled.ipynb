{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import grad\n",
    "import pandas as pd\n",
    "from InverseFuncs import trajectory, getLoss, reset_theta, theta_range\n",
    "\n",
    "from DDPGv2Agent import Agent\n",
    "from FireflyEnv import Model # firefly_task.py\n",
    "from collections import deque\n",
    "from Inverse_Config import Inverse_Config\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# read configuration parameters\n",
    "arg = Inverse_Config()\n",
    "# fix random seed\n",
    "import random\n",
    "random.seed(arg.SEED_NUMBER)\n",
    "import torch\n",
    "torch.manual_seed(arg.SEED_NUMBER)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(arg.SEED_NUMBER)\n",
    "import numpy as np\n",
    "np.random.seed(arg.SEED_NUMBER)\n",
    "import time\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# if gpu is to be used\n",
    "#CUDA = False\n",
    "#device = \"cpu\"\n",
    "\n",
    "CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "\n",
    "\n",
    "filename = '20191231-172726-01081157' # agent information\n",
    "\n",
    "learning_arg = torch.load('../firefly-inverse-data/data/20191231-172726_arg.pkl')\n",
    "\n",
    "DISCOUNT_FACTOR = learning_arg.DISCOUNT_FACTOR\n",
    "arg.gains_range = learning_arg.gains_range\n",
    "arg.std_range = learning_arg.std_range\n",
    "arg.goal_radius_range = learning_arg.goal_radius_range\n",
    "arg.WORLD_SIZE = learning_arg.WORLD_SIZE\n",
    "arg.DELTA_T = learning_arg.DELTA_T\n",
    "arg.EPISODE_TIME = learning_arg.EPISODE_TIME\n",
    "arg.EPISODE_LEN = learning_arg.EPISODE_LEN\n",
    "\n",
    "\n",
    "\n",
    "env = Model(arg) # build an environment\n",
    "env.max_goal_radius = arg.goal_radius_range[1] # use the largest world size for goal radius\n",
    "env.box = arg.WORLD_SIZE\n",
    "agent = Agent(env.state_dim, env.action_dim, arg,  filename, hidden_dim=128, gamma=DISCOUNT_FACTOR, tau=0.001) #, device = \"cpu\")\n",
    "agent.load(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_space = np.linspace(arg.gains_range[0],arg.gains_range[1], num = 5)\n",
    "std_space = np.linspace(arg.std_range[0], arg.std_range[1], num = 3)\n",
    "goal_radius_spce = np.linspace(arg.goal_radius_range[0], arg.goal_radius_range[1], num =3)\n",
    "theta_log = []\n",
    "loss_log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true theta\n",
    "true_theta = reset_theta(arg.gains_range, arg.std_range, arg.goal_radius_range)\n",
    "true_theta_log.append(true_theta.data.clone())\n",
    "x_traj, obs_traj, a_traj, _ = trajectory(agent, true_theta, env, arg, arg.gains_range, arg.std_range,arg.goal_radius_range, arg.NUM_EP)  # generate true trajectory\n",
    "true_loss = getLoss(agent, x_traj, a_traj, true_theta, env, arg.gains_range, arg.std_range, arg.PI_STD, arg.NUM_SAMPLES)  # this is the lower bound of loss?\n",
    "print(\"true loss:{}\".format(true_loss))\n",
    "print(\"true_theta:{}\".format(true_theta))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pro_gains_vel, pro_gains_ang, obs_gains_vel, obs_gains_ang, pro_std_vel, pro_std_ang, obs_std_vel, obs_std_ang, goal_radius in zip(gain_space, gain_space, gain_space, gain_space, std_space, std_space, std_space, std_space, goal_radius_spce):\n",
    "    \n",
    "    theta = torch.cat([pro_gains_vel, pro_gains_ang, pro_std_vel, pro_std_ang, obs_gains_vel, obs_gains_ang, pro_std_vel, pro_std_ang, goal_radius])\n",
    "    theta_log.append(theta.data)\n",
    "    loss = getLoss(agent, x_traj, a_traj, theta, env, arg.gains_range, arg.std_range, arg.PI_STD, arg.NUM_SAMPLES)\n",
    "    loss_log.append(loss.data)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5**4 * 3**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
